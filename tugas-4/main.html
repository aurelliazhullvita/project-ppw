
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Word embedding</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tugas-4/main';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="&lt;no title&gt;" href="../tugas-5/main.html" />
    <link rel="prev" title="Implementasi hasil VSM dengan algoritma Logistic Regression" href="../tugas-3/main.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt="My sample book - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to Project PPW
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
          <li class="toctree-l1"><a class="reference internal" href="../tugas-1/main.html"><strong>Tugas 1</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../tugas-2/main.html"><strong>Tugas 2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../tugas-3/main.html"><strong>Tugas 3</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../tugas-4/main.html"><strong>Tugas 4</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../tugas-5/main.html"><strong>Tugas 5</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../tugas-6/main.html"><strong>Tugas 6</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../tugas-7/main.html"><strong>Tugas 7</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../tugas-8/main.html"><strong>Tugas 8</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../tugas_akhir/main.html"><strong>Tugas Akhir</strong></a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Ftugas-4/main.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/tugas-4/main.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Word embedding</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-gram">Skip-Gram</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#crow-continues-bag-of-word">CROW (continues Bag of word)</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="word-embedding">
<h1>Tugas 4 | Word embedding<a class="headerlink" href="#word-embedding" title="Link to this heading">#</a></h1>
<section id="skip-gram">
<h2>Skip-Gram<a class="headerlink" href="#skip-gram" title="Link to this heading">#</a></h2>
</section>
<section id="crow-continues-bag-of-word">
<h2>CROW (continues Bag of word)<a class="headerlink" href="#crow-continues-bag-of-word" title="Link to this heading">#</a></h2>
<p>Skip Gram merupakan sebuah sebuah arsitektur dalam menentukan nilai vector suatu kata dengan memprediksi kata-kata yang mungkin muncul jika diberikan suatu kata sebagai input-nya.</p>
<p>Model Skip-Gram adalah pendekatan jaringan saraf yang digunakan dalam pemrosesan bahasa alami untuk memprediksi konteks (kata-kata di sekitarnya) dari kata target tertentu. Model ini berfokus pada memaksimalkan kemungkinan kata konteks muncul di sekitar kata target.</p>
<p><strong>Tujuan :</strong>
Model Skip-Gram bertujuan untuk memprediksi kata-kata kontekstual yang mengelilingi kata target tertentu dalam jendela tertentu. Misalnya, dalam kalimat “Kucing duduk di atas tikar,” jika “kucing” adalah kata target, model akan mencoba memprediksi kata-kata di sekitarnya seperti “Kucing”, “duduk”, dll., dalam ukuran jendela yang ditentukan.</p>
<p><strong>Arsitektur :</strong></p>
<ul class="simple">
<li><p>Lapisan Input : Vektor yang dikodekan one-hot mewakili kata target.</p></li>
<li><p>Lapisan Tersembunyi : Lapisan tersembunyi yang padat mengubah vektor masukan menjadi representasi berdimensi lebih rendah, yang umumnya disebut sebagai penyisipan kata.</p></li>
<li><p>Output Layer : Jaringan memprediksi kata konteks berdasarkan embedding yang dihasilkan oleh hidden layer. Kata konteks ini juga direpresentasikan sebagai distribusi probabilitas menggunakan fungsi softmax.</p></li>
</ul>
<p><strong>Pelatihan :</strong>
Selama pelatihan, model Skip-Gram memperbarui penyertaan dengan meminimalkan kerugian (seringkali melalui Pengambilan Sampel Negatif, yang mengurangi kerumitan komputasi dengan berfokus pada prediksi yang salah).
Proses ini melibatkan propagasi maju untuk memprediksi kata konteks dan propagasi balik untuk menyesuaikan bobot berdasarkan kesalahan antara kata konteks yang diprediksi dan aktual.</p>
<ul class="simple">
<li><p>Penanaman Kata : Model Skip-Gram menghasilkan penanaman kata berkualitas tinggi di mana kata-kata dengan makna yang serupa memiliki representasi yang serupa dalam ruang vektor. Misalnya, “kucing” dan “anjing” mungkin berdekatan satu sama lain dalam ruang penanaman karena keduanya adalah hewan.</p></li>
<li><p>Skip-Gram vs CBOW : Skip-Gram berbeda dari Continuous Bag of Words (CBOW). Sementara CBOW memprediksi kata target dari kata konteks di sekitarnya, Skip-Gram bekerja secara terbalik dengan memprediksi kata konteks dari kata target.</p></li>
<li><p>Tantangan : Meskipun efektif, Skip-Gram dapat memakan banyak biaya komputasi ketika kosakatanya besar, memerlukan teknik seperti pengambilan sampel negatif agar prosesnya efisien.</p></li>
</ul>
<p>Berikut adalah contoh input dan output untuk representasi vektor kata menggunakan model Word2Vec atau Skip-Gram:</p>
<p><strong>Input:</strong>
contoh pemilihan kata input misalnya :
“saya suka bermain sepak bola di lapangan besar”</p>
<p>langkah - langkah yang dilakukan oleh model Word2Vec dengan pendekatan Skip-Gram:</p>
<ol class="arabic">
<li><p>Tokenisasi: Kalimat tersebut akan diubah menjadi kumpulan kata:</p>
<p>[“saya”, “suka”, “bermain”, “sepak”, “bola”, “di”, “lapangan”, “besar”]</p>
</li>
<li><p>Window Size: Untuk setiap kata, kita akan memilih konteks kata di sekitarnya dengan jendela tertentu, misalnya jendela ukuran 2 (dua kata sebelum dan sesudah).</p></li>
<li><p>Pasangan kata (word pairs): Model Skip-Gram bertujuan untuk memprediksi konteks dari kata pusat (target). Pasangan yang dihasilkan dari kalimat dengan jendela 2 adalah:</p>
<p>(“saya”, “suka”), (“saya”, “bermain”)
(“suka”, “saya”), (“suka”, “bermain”), (“suka”, “sepak”)
(“bermain”, “suka”), (“bermain”, “sepak”), (“bermain”, “bola”)
(“sepak”, “bermain”), (“sepak”, “bola”), (“sepak”, “di”)
(“bola”, “sepak”), (“bola”, “di”), (“bola”, “lapangan”)
(“di”, “bola”), (“di”, “lapangan”), (“di”, “besar”)
(“lapangan”, “di”), (“lapangan”, “besar”)
(“besar”, “lapangan”), (“besar”, “di”)</p>
</li>
<li><p>Setelah model Skip-Gram dilatih, kita mendapatkan representasi vektor untuk setiap kata.
Pemilihan ukuran jendela yang tepat tergantung pada beberapa faktor:</p></li>
</ol>
<p><strong>Output:</strong>
Model Word2Vec dengan pendekatan Skip-Gram menghasilkan vektor berdimensi tinggi untuk setiap kata dalam kamus (vocabulary) berdasarkan kemunculan bersama mereka dalam konteks tertentu.</p>
<p>Misalkan kita ingin melihat representasi vektor dari kata “sepak”, outputnya bisa berupa vektor seperti ini (dengan dimensi, misalnya, 100):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;sepak&quot;: [0.423, -0.237, 0.101, ..., 0.054, -0.134, 0.876]
</pre></div>
</div>
<p>Vektor ini adalah representasi kata “sepak” dalam ruang vektor berdimensi tinggi, yang dapat digunakan untuk menghitung kesamaan antar kata (misalnya menggunakan cosine similarity).</p>
<p><strong>Contoh Kesamaan Kata:</strong>
jika ingin menghitung kesamaan antara kata “sepak” dan “bola”, maka model akan menghasilkan nilai kesamaan tertentu. Misalnya:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>similarity(&quot;sepak&quot;, &quot;bola&quot;) = 0.89
</pre></div>
</div>
<p>Nilai ini menunjukkan bahwa kedua kata tersebut cukup mirip dalam konteks tertentu, seperti yang dipelajari oleh model.</p>
<p>rumus-rumus yang terkait:</p>
<ol class="arabic simple">
<li><p>Turunan fungsi biaya
$<span class="math notranslate nohighlight">\(
\underset{\theta}{\text{argmax}} \,\, p(w_{1}, w_{2}, ... , w_{C}|w_{center}; \, \theta) \tag{1}
\)</span>$</p></li>
</ol>
<p><em>penjelasan rumus di atas:</em></p>
<ul class="simple">
<li><p>simbol argmax𝜃 menunjukkan bahwa ingin menemukan nilai parameter 𝜃 memaksimalkan fungsi probabilitas. dalam konteks ini sedang mencari parameter 𝜃 yang memaksimalkan probabilitas kata - kata konteks w1,w2,….,Wc yang muncul berdasarkan kata pusat Wcenter</p></li>
<li><p>probabilitas bersyarat p(w1,w2,…Wc|wcenter;𝜃) dari kata kata konteks w1,w2,…wc yang muncul berdasarkan kata pusat wcenter, dengan parameter 𝜃.</p></li>
<li><p>kata pusat dan kata konteks, Wcenter adalah kata pusat (kata yang fokus atau acuan). W1,W2,….Wc adalah kata kata konteks yaitu kata kata yang muncul di sekitar kata pusat dalam jendela konteks tertentu.</p></li>
<li><p>parameter 𝜃
θ mewakili parameter model yang sedang di optimalkan. word2Vec (terutama pendekatan skip-gram),parameter 𝜃
adalah embedding vektor atau representasi vektor dari kata - kata dalam ruang berdimensi tinggi.</p></li>
<li><p>skip gram model dari word2Vec,tujuan utamanya adalam untuk memprediksi kata kata konteks W1,W2,…,Wc berdasarkan kata pusat Wcenter. dalam rumus ini, kita mencoba menemukan parameter 𝜃 (vektor kata) yang memaksimalkan probabilitas bahwa kata kata konteks yang ada di sekitar kata pusat</p></li>
<li><p>seperti contoh di atas, jika kata pusat adalah “sepak”, model mencoba memaksimalkan probabilitas bahwa kata-kata konteks seperti “bola”, “lapangan”, atau “tim” muncul di sekitarnya. Dengan melatih parameter
𝜃 (embedding vektor) model berusaha mempelajari hubungan antara kata-kata tersebut.</p></li>
</ul>
<p><strong>Forward Propagation: Hidden (Projection) Layer (h)</strong>
<img alt="image" src="https://hackmd.io/_uploads/Hy0vpdHR0.png" />
Dalam konsep Natural Language Prosessing hidden layer dapat disebut sebagai projection layer. Dikarenakan h
itu sebenarnya <span class="math notranslate nohighlight">\(N-\)</span>dim projected vector dari one hot encoding dari input vektor h</p>
<p><span class="math notranslate nohighlight">\(\begin{align*} h = W_{input}^T \cdot x \in \mathbb{R}^{N} \end{align*}\)</span></p>
<p>** Forward Propagation: Softmax Output Layer**
Output layer berisi probabilitas dari semua kata unik dalam corpus (<span class="math notranslate nohighlight">\({V-}\)</span>dim). Untuk menentukan nilai probabilitas diperlukan kata konteks dan kata target</p>
<p><span class="math notranslate nohighlight">\(\begin{align*} p(w_{context}|w_{center}) = \frac{exp(W_{output_{(context)}} \cdot h)}{\sum^V_{i=1}exp(W_{output_{(i)}} \cdot h)} \in \mathbb{R}^{1} \end{align*}\)</span></p>
<ul class="simple">
<li><p>Woutput(i) adalah nilai elemen vektor output dari kata ke-<span class="math notranslate nohighlight">\({i}\)</span> yang memiliki ukuran 1×N</p></li>
<li><p>woutput context adalah nilai elemen vektor output dari kata konteks yang juga memiliki ukuran 1×N</p></li>
<li><p>V adalah total kata unik dari corpus</p></li>
<li><p>h adalah hidden (projection) layer yang memiliki ukuran (N×1)</p></li>
<li><p>Output yang dihasilkan adalah nilai skalar dengan ukuran(1×1)yang memiliki probabilitas dengan rentang [0,1]</p></li>
</ul>
<p>Proses ini akan melakukan perulangan sejumlah V kali sesuai dengan jumlah kata unik dalam corpus dengan kata target.</p>
<p><span class="math notranslate nohighlight">\(\begin{align*} \left[\begin{array}{c} p(w_{1}|w_{center}) \ p(w_{2}|w_{center}) \ p(w_{3}|w_{center}) \ \vdots \ p(w_{V}|w_{center}) \end{array} \right] = \frac{exp(W_{output} \cdot h)}{\sum^V_{i=1}exp(W_{output_{(i)}} \cdot h)} \in \mathbb{R}^{V} \end{align*}\)</span></p>
<p>Sehingga Woutput yang memiliki ukuran(V×N) akan dikalikan dengan h yang memiliki ukuran (N×1)sehingga menghasilkan dot product vector yang memiliki ukuran (V×1).Terakhir, dot product vector akan dimasukkan ke dalam fungsi aktivasi softmax.
<img alt="image" src="https://hackmd.io/_uploads/SJFE1cr0R.png" />
Hasil nilai dari aktivasi softmax jika dijumlahkan semua akan bernilai 1.</p>
<p><strong>Backward Propagation: Prediction Error</strong>
Skip-Gram model melakukan optimasi bobot matriks (θ) dengan mengurangi prediction error. Prediction error merupakan perbedaan antara hasil dari softmax output layer (ypred) dengan probabilitas target yang sebenarnya (ytrue) dari setiap kata. ytrue merupakan vektor one hot encoder dari setiap kata konteks.
<img alt="image" src="https://hackmd.io/_uploads/SJ5lxcH0C.png" />
terdapat 2 kata yaitu “the” dan “who” yang telah memiliki hasil dari pengurangan
ypred dan ytrue. Selanjutnya dilakukan penjumlahan untuk melihat bobot yang kemudian akan dimasukkan/diupdate pada matriks bobot yang ada.
<img alt="image" src="https://hackmd.io/_uploads/B1gNxcHRA.png" />
Update matriks bobot terus dilakukan hingga mendapatkan prediction error paling kecil.
<img alt="image" src="https://hackmd.io/_uploads/H1oSxqS0R.png" /></p>
<p><strong>Demonstrasi Perhitungan</strong></p>
<ol class="arabic simple">
<li><p>Mencari nilai hidden layer (h):
<img alt="image" src="https://hackmd.io/_uploads/Syc3l5S0C.png" /></p></li>
<li><p>Menghitung output layer dengan fungsi aktivasi softmax:
<img alt="image" src="https://hackmd.io/_uploads/HkwZW5BAC.png" /></p></li>
<li><p>Menjumlahkan prediction error dari kata konteks:
<img alt="image" src="https://hackmd.io/_uploads/SymQW9BAR.png" /></p></li>
<li><p>Mengitung ∇Winput :
rumus yang dapat direpresentasikan juga dengan cara mengalikan vektor one hot encoding dari input layer (x) dengan WoutputT∑c=1Cec. Rumus WoutputT∑c=1Cec merupakan hasil perkalian antara (Woutput) dengan penjumlahan prediction error (∑c=1Cec).
<span class="math notranslate nohighlight">\(\begin{align*} \frac{\partial J}{\partial W_{input}} = x \cdot (W_{output}^T \sum^C_{c=1} e_c) \end{align*}\)</span>
<img alt="image" src="https://hackmd.io/_uploads/BkMfzqrC0.png" /></p></li>
<li><p>Menghitung ∇Woutput :
yang dapat direprenstasikan juga dengan cara mengalikan hidden layer (h) dengan penjumlahan prediction error (∑c=1Cec). Tidak sama dengan matriks bobot input (Winput) yang hanya mengupdate satu nilai vektor, tetapi semua nilai vektor pada matriks bobot output (Woutput) akan diperbarui.
<span class="math notranslate nohighlight">\(\begin{align*} \frac{\partial J}{\partial W_{output}} = h \cdot \sum^C_{c=1} e_c \end{align*}\)</span>
<img alt="image" src="https://hackmd.io/_uploads/r1Kif9BRC.png" /></p></li>
<li><p>Memperbarui matriks bobot input dan output :
Matriks bobot input dan output akan diperbarui menggunakan rumus</p></li>
</ol>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\begin{align*} W_{input}^{(new)}=W_{input}^{(old)}- \eta \cdot x \cdot (W_{output}^T \sum^C_{c=1} e_c) \end{align*}\)</span>
<img alt="image" src="https://hackmd.io/_uploads/Hy-Jm5SA0.png" /></p></li>
<li><p><span class="math notranslate nohighlight">\(\begin{align*} W_{output}^{(new)}=W_{output}^{(old)}- \eta \cdot h \cdot \sum^C_{c=1} e_c \end{align*}\)</span>
<img alt="image" src="https://hackmd.io/_uploads/BJJMQ9SC0.png" /></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tugas-4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../tugas-3/main.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Tugas 3</p>
      </div>
    </a>
    <a class="right-next"
       href="../tugas-5/main.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Tugas 5</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-gram">Skip-Gram</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#crow-continues-bag-of-word">CROW (continues Bag of word)</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Aurellia Zhullvita Amanullah-220411100200
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Teknik Informatika-2024
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
